{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal                  1824\n",
      "Command Injection TL     253\n",
      "Command Injection TH      62\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ML related\n",
    "from time import sleep, thread_time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# system requirements\n",
    "import os, sys\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "path = \"/home/abuyusif01/dev/dtss/dt/fp/src/clean_logs/\"\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, \"*_label.csv\"))\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# we bascially drop the time column\n",
    "fit_cols = df.select_dtypes(include=[\"float64\", \"int64\"])\n",
    "scale_df = scaler.fit_transform(fit_cols)\n",
    "train_x = pd.DataFrame(scale_df, columns=fit_cols.columns)\n",
    "train_y = df[\"class\"]\n",
    "\n",
    "# Train ML model\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    test_size=0.7,\n",
    "    random_state=1,\n",
    "    stratify=train_y,\n",
    ")\n",
    "\n",
    "df_analysis = pd.concat([x_test, y_test], axis=1)\n",
    "print(df[\"class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. RandomForest Model Test Results\n",
    "import pickle\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = OneVsRestClassifier(\n",
    "    RandomForestClassifier(\n",
    "        random_state=1,\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "    )\n",
    ")\n",
    "\n",
    "random_forest.fit(x_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GB Model Test Results\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = OneVsRestClassifier(\n",
    "    GradientBoostingClassifier(\n",
    "        random_state=1,\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "    )\n",
    ")\n",
    "gb.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model Test Results\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        random_state=1,\n",
    "        max_iter=10000,\n",
    "        solver=\"lbfgs\",\n",
    "    )\n",
    ")\n",
    "logistic.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Model Test Results\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naive_bayes = OneVsRestClassifier(\n",
    "    GaussianNB()\n",
    ")\n",
    "naive_bayes.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Stacking Model Test Results\n",
    "# change final_estimator to minimum 2 models\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "stacking = OneVsRestClassifier(\n",
    "    StackingClassifier(\n",
    "        estimators=[\n",
    "            (\"rf\", random_forest),\n",
    "            (\"gb\", gb),\n",
    "            (\"logistic\", logistic),\n",
    "            (\"naive_bayes\", naive_bayes),\n",
    "        ],\n",
    "        final_estimator=MLPClassifier(\n",
    "            random_state=1,\n",
    "            max_iter=10000,\n",
    "            hidden_layer_sizes=(100, 100),\n",
    "            solver=\"lbfgs\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "stacking.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, warnings\n",
    "from turtle import color, title\n",
    "\n",
    "import pickle  # dump model\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "FIG_SIZE = 7.5\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred, title, labels, color, normalize=False):\n",
    "    if normalize == False:\n",
    "        ConfusionMatrixDisplay.from_predictions(\n",
    "            y_test,\n",
    "            y_pred,\n",
    "            labels=labels,\n",
    "            cmap=color,\n",
    "            xticks_rotation=\"vertical\",\n",
    "        )\n",
    "\n",
    "        return\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        labels=labels,\n",
    "        cmap=color,\n",
    "        normalize=\"true\",\n",
    "        xticks_rotation=\"vertical\",\n",
    "    )\n",
    "    return\n",
    "    # cm.plot()\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append((\"rf\", random_forest))\n",
    "models.append((\"naive_bayes\", naive_bayes))\n",
    "models.append((\"stacking\", stacking))\n",
    "models.append((\"gb\", gb))\n",
    "models.append((\"logistic\", logistic))\n",
    "\n",
    "\n",
    "models_name = [\n",
    "    \"randomForest\",\n",
    "    \"naive_bayes\",\n",
    "    \"stacking\",\n",
    "    \"gradientBoost\",\n",
    "    \"logistic\",\n",
    "]\n",
    "labels = [\n",
    "    \"Normal\",\n",
    "    \"Command Injection TL\",\n",
    "    \"Command Injection TH\",\n",
    "]\n",
    "\n",
    "model_test_accuracy = []\n",
    "model_test_precision = []\n",
    "model_test_recall = []\n",
    "model_test_f1 = []\n",
    "\n",
    "\n",
    "for x, y in models:\n",
    "    y.fit(x_train, y_train)\n",
    "    y_pred = y.predict(x_test)\n",
    "    y_pred_proba = y.predict_proba(x_test)[:, 1]\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = sklearn.metrics.precision_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = sklearn.metrics.recall_score(y_test, y_pred, average=\"macro\")\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "    f1 = sklearn.metrics.f1_score(\n",
    "        y_test, y_pred, average=\"macro\", labels=np.unique(y_pred)\n",
    "    )\n",
    "\n",
    "    # append algorithm overall test results to list\n",
    "    model_test_accuracy.append(accuracy)\n",
    "    model_test_precision.append(precision)\n",
    "    model_test_recall.append(recall)\n",
    "    model_test_f1.append(f1)\n",
    "    sklearn.metrics.multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # dump model\n",
    "    pickle.dump(y, open(\"pkl_files/\" + x + \".pkl\", \"wb\"))\n",
    "\n",
    "    print(\n",
    "        \"\"\"\n",
    "        Model: %s \n",
    "        Dataset size: %s\n",
    "        Accuracy: %f\n",
    "        Precision: %f\n",
    "        Recall: %f\n",
    "        F1: %f\n",
    "        \"\"\"\n",
    "        % (\n",
    "            x,\n",
    "            len(df),\n",
    "            accuracy,\n",
    "            precision,\n",
    "            recall,\n",
    "            f1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # overall plot_confusion_matrix\n",
    "    plot_confusion_matrix(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        x,\n",
    "        labels,\n",
    "        plt.cm.Blues,\n",
    "    )\n",
    "\n",
    "# plot dash graph\n",
    "fig, axes = plt.subplots(figsize=(FIG_SIZE, FIG_SIZE))\n",
    "axes.title.set_text(\"Accuracy of Models\")\n",
    "axes.plot(\n",
    "    models_name,\n",
    "    model_test_accuracy,\n",
    "    label=\"Accuracy\",\n",
    "    marker=\"o\",\n",
    "    color=\"blue\",\n",
    "    linestyle=\"dashed\",\n",
    ")\n",
    "\n",
    "\n",
    "# plot histogram\n",
    "fig, axes = plt.subplots(figsize=(FIG_SIZE, FIG_SIZE))\n",
    "axes.bar(models_name, model_test_accuracy)\n",
    "axes.set_title(\"Accuracy\")\n",
    "axes.set_ylabel(\"Accuracy\")\n",
    "axes.set_xlabel(\"Algorithms\")\n",
    "axes.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# float a pie chart\n",
    "fig, axes = plt.subplots(figsize=(FIG_SIZE, FIG_SIZE))\n",
    "axes.pie(\n",
    "    model_test_accuracy,\n",
    "    labels=models_name,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    ")\n",
    "axes.grid(True)\n",
    "axes.set_title(\"Accuracy Comparison\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
